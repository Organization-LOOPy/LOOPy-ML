# app/core/config.py
import os
import sys
from typing import List, Optional, Any, Dict
from pydantic import validator, Field
from pydantic_settings import BaseSettings
from functools import lru_cache
import logging

class Settings(BaseSettings):
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì •"""
    
    # í™˜ê²½ ì„¤ì •
    environment: str = Field(default="dev")
    
    # ì•± ì„¤ì •
    app_name: str = Field(default="AI Processing Service")
    version: str = Field(default="1.0.0")
    description: str = Field(default="FastAPI ë‚´ë¶€ AI ì„œë¹„ìŠ¤")
    
    # ì„œë²„ ì„¤ì •
    host: str = Field(default="127.0.0.1")
    port: int = Field(default=8001)
    workers: int = Field(default=2)
    
    # ë¡œê¹… ì„¤ì •
    log_format: str = Field(default="%(asctime)s - %(name)s - %(levelname)s - %(message)s")
    
    # CORS ì„¤ì •
    dev_cors_origins: List[str] = Field(
        default=["http://localhost:3000", "http://127.0.0.1:3000", "http://localhost:5137"]
    )
    prod_cors_origins: List[str] = Field(
        default=["http://localhost:3000", "http://localhost:5137"]
    )
    prod_cors_headers: List[str] = Field(
        default=["Content-Type", "X-Internal-API-Key", "X-User-ID", "X-User-Role", "X-Session-ID", "X-User-Permissions"]
    )
    
    # ë³´ì•ˆ ì„¤ì •
    internal_api_key: Optional[str] = Field(default=None)
    allowed_hosts: List[str] = Field(default=["127.0.0.1", "localhost"])
    
    # OpenAI ì„¤ì •
    openai_api_key: Optional[str] = Field(default=None)
    openai_model: str = Field(default="gpt-3.5-turbo")
    openai_max_tokens: int = Field(default=1000)
    openai_temperature: float = Field(default=0.7)
    
    # í•œêµ­ì–´ ì„ë² ë”© ëª¨ë¸ ì„¤ì •
    korean_embedding_model: str = Field(default="jhgan/ko-sroberta-multitask")
    korean_sentence_model: str = Field(default="snunlp/KR-SBERT-V40K-klueNLI-augSTS")
    
    # NLP ì²˜ë¦¬ ì„¤ì •
    max_sequence_length: int = Field(default=512)
    batch_size: int = Field(default=32)
    similarity_threshold: float = Field(default=0.7)
    top_k_results: int = Field(default=10)
    
    # ëª¨ë¸ ìºì‹± ì„¤ì •
    model_cache_dir: str = Field(default="./models")
    enable_model_cache: bool = Field(default=True)
    model_download_timeout: int = Field(default=300)
    
    # ë°ì´í„° ì„¤ì •
    data_dir: str = Field(default="./data")
    index_dir: str = Field(default="./data/index")
    
    # ì„±ëŠ¥ ì„¤ì •
    use_gpu: bool = Field(default=False)
    num_threads: int = Field(default=4)
    request_timeout: int = Field(default=30)
    
    class Config:
        env_file = ".env"
        env_file_encoding = "utf-8"
        case_sensitive = False
        
    # ê²€ì¦
    @validator("environment")
    def validate_environment(cls, v):
        allowed = ["dev", "prod", "test"]
        if v.lower() not in allowed:
            raise ValueError(f"environment must be one of {allowed}")
        return v.lower()
    
    @validator("similarity_threshold")
    def validate_similarity_threshold(cls, v):
        if not 0.0 <= v <= 1.0:
            raise ValueError("similarity_threshold must be between 0.0 and 1.0")
        return v
    
    @validator("openai_temperature")
    def validate_temperature(cls, v):
        if not 0.0 <= v <= 2.0:
            raise ValueError("openai_temperature must be between 0.0 and 2.0")
        return v
    
    # ê³„ì‚°ëœ ì†ì„±ë“¤
    @property
    def is_production(self) -> bool:
        return self.environment == "prod"
    
    @property
    def is_development(self) -> bool:
        return self.environment == "dev"
    
    @property
    def debug(self) -> bool:
        return not self.is_production
    
    @property
    def log_level(self) -> int:
        return logging.INFO if self.is_production else logging.DEBUG
    
    @property
    def docs_url(self) -> Optional[str]:
        return "/docs" if not self.is_production else None
    
    @property
    def redoc_url(self) -> Optional[str]:
        return "/redoc" if not self.is_production else None
    
    @property
    def server_url(self) -> str:
        return f"http://{self.host}:{self.port}"
    
    # í™˜ê²½ë³„ ì„¤ì • ë©”ì„œë“œë“¤
    def get_cors_settings(self) -> Dict[str, Any]:
        if self.is_production:
            return {
                "allow_origins": self.prod_cors_origins,
                "allow_credentials": False,
                "allow_methods": ["GET", "POST"],
                "allow_headers": self.prod_cors_headers,
            }
        else:
            return {
                "allow_origins": self.dev_cors_origins,
                "allow_credentials": True,
                "allow_methods": ["*"],
                "allow_headers": ["*"],
            }
    
    def get_uvicorn_settings(self) -> Dict[str, Any]:
        if self.is_production:
            return {
                "host": self.host,
                "port": self.port,
                "log_level": "info",
                "access_log": False,
                "workers": self.workers
            }
        else:
            return {
                "host": self.host,
                "port": self.port,
                "reload": True,
                "log_level": "debug", 
                "access_log": True
            }
    
    def get_fastapi_settings(self) -> Dict[str, Any]:
        return {
            "title": self.app_name,
            "version": self.version,
            "description": self.description,
            "debug": self.debug,
            "docs_url": self.docs_url,
            "redoc_url": self.redoc_url
        }
    
    # í•œêµ­ì–´ ëª¨ë¸ ê´€ë ¨ ë©”ì„œë“œë“¤
    def get_korean_model_config(self, model_type: str = "default") -> Dict[str, Any]:
        """í•œêµ­ì–´ ëª¨ë¸ ì„¤ì • ë°˜í™˜"""
        model_configs = {
            "default": {
                "model_name": self.korean_embedding_model,
                "max_length": self.max_sequence_length,
                "batch_size": self.batch_size
            },
            "sentence": {
                "model_name": self.korean_sentence_model,
                "max_length": self.max_sequence_length,
                "batch_size": self.batch_size
            },
            "search": {
                "model_name": self.korean_embedding_model,
                "max_length": self.max_sequence_length,
                "batch_size": self.batch_size,
                "similarity_threshold": self.similarity_threshold,
                "top_k": self.top_k_results
            }
        }
        
        return model_configs.get(model_type, model_configs["default"])
    
    def get_device_config(self) -> Dict[str, Any]:
        """ë””ë°”ì´ìŠ¤ ì„¤ì • ë°˜í™˜"""
        try:
            import torch
            if self.use_gpu and torch.cuda.is_available():
                device = "cuda"
                device_count = torch.cuda.device_count()
            else:
                device = "cpu"
                device_count = 1
        except ImportError:
            device = "cpu"
            device_count = 1
        
        return {
            "device": device,
            "device_count": device_count,
            "num_threads": self.num_threads if device == "cpu" else None
        }
    
    # ìœ í‹¸ë¦¬í‹° ë©”ì„œë“œë“¤
    def create_directories(self):
        """í•„ìš”í•œ ë””ë ‰í† ë¦¬ë“¤ ìƒì„±"""
        directories = [self.data_dir, self.model_cache_dir, self.index_dir]
        for directory in directories:
            os.makedirs(directory, exist_ok=True)
    
    def print_settings(self):
        """í˜„ì¬ ì„¤ì • ì •ë³´ ì¶œë ¥"""
        print("=" * 60)
        print(f"ğŸŒ Environment: {self.environment}")
        print(f"ğŸ·ï¸  App Name: {self.app_name}")
        print(f"ğŸ“Š Version: {self.version}")
        print(f"ğŸ–¥ï¸  Server: {self.server_url}")
        print(f"ğŸ“Š Log Level: {'INFO' if self.is_production else 'DEBUG'}")
        print(f"ğŸ”§ Debug: {self.debug}")
        print("â”€" * 60)
        print("ğŸ‡°ğŸ‡· í•œêµ­ì–´ AI ëª¨ë¸ ì„¤ì •:")
        print(f"   ğŸ“ ê¸°ë³¸ ì„ë² ë”©: {self.korean_embedding_model}")
        print(f"   ğŸ“„ ë¬¸ì¥ ì„ë² ë”©: {self.korean_sentence_model}")
        print(f"   ğŸ’¾ ëª¨ë¸ ìºì‹œ: {self.model_cache_dir}")
        print(f"   ğŸ¯ GPU ì‚¬ìš©: {self.use_gpu}")
        if not self.is_production:
            print(f"ğŸ“– API Docs: {self.server_url}/docs")
        print("=" * 60)


def get_environment_from_args() -> str:
    """ëª…ë ¹í–‰ ì¸ì ë˜ëŠ” í™˜ê²½ë³€ìˆ˜ì—ì„œ í™˜ê²½ ì„¤ì • ê°€ì ¸ì˜¤ê¸°"""
    if len(sys.argv) > 1 and sys.argv[1] in ["dev", "prod"]:
        return sys.argv[1].lower()
    return os.getenv("ENVIRONMENT", "dev").lower()


@lru_cache()
def get_settings() -> Settings:
    """ì„¤ì • ê°ì²´ ë°˜í™˜ (ìºì‹œë¨)"""
    env = get_environment_from_args()
    os.environ["ENVIRONMENT"] = env
    return Settings()


def initialize_settings() -> Settings:
    """ì„¤ì • ì´ˆê¸°í™” ë° í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±"""
    settings = get_settings()
    settings.create_directories()
    
    if settings.is_development:
        settings.print_settings()
    
    return settings


if __name__ == "__main__":
    settings = initialize_settings()
    print("\nğŸ‡°ğŸ‡· í•œêµ­ì–´ ëª¨ë¸ ì„¤ì •:")
    print(f"ê¸°ë³¸ ëª¨ë¸: {settings.get_korean_model_config('default')}")
    print(f"ê²€ìƒ‰ ëª¨ë¸: {settings.get_korean_model_config('search')}")
    print(f"ë””ë°”ì´ìŠ¤: {settings.get_device_config()}")